{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574b80e-58a4-4298-b8ff-7e6ca928538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "# Загрузка модели TFLite\n",
    "interpreter = tf.lite.Interpreter(model_path=\"models/volov8_model_v4.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Получение информации о входных и выходных тензорах\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Функция предобработки изображения\n",
    "def preprocess_image(image, input_shape):\n",
    "    image = cv2.resize(image, (input_shape[1], input_shape[2]))\n",
    "    image = image.astype(np.float32)\n",
    "    image = image / 255.0  # нормализация\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Функция постобработки результатов (пример для YOLO)\n",
    "def postprocess_output(output_data, img_width, img_height):\n",
    "    # Пример обработки выходных данных (зависит от вашей модели)\n",
    "    boxes, scores, classes = [], [], []\n",
    "    for detection in output_data[0]:\n",
    "        score = detection[4]\n",
    "        if score > 0.5:\n",
    "            box = detection[:4] * np.array([img_width, img_height, img_width, img_height])\n",
    "            boxes.append(box.astype(int))\n",
    "            scores.append(score)\n",
    "            classes.append(int(detection[5]))\n",
    "    return boxes, scores, classes\n",
    "\n",
    "# Инициализация камеры\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    input_shape = input_details[0]['shape']\n",
    "    img_height, img_width, _ = frame.shape\n",
    "\n",
    "    # Предобработка кадра\n",
    "    input_data = preprocess_image(frame, input_shape)\n",
    "\n",
    "    # Установка данных в тензор\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    # Выполнение инференса\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Получение результатов\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    boxes, scores, classes = postprocess_output(output_data, img_width, img_height)\n",
    "\n",
    "    # Отображение результатов на кадре\n",
    "    for box, score, cls in zip(boxes, scores, classes):\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        label = f\"Class {cls}: {score:.2f}\"\n",
    "        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Отображение кадра\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "\n",
    "    # Выход по нажатию клавиши 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
